{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08edd5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# パスをsys.pathに追加\n",
    "sys.path.append(\"/p-antipsychotics-sleep/\")\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faster2lib.eeg_tools as et\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from scipy import signal\n",
    "from hmmlearn import hmm, base\n",
    "from sklearn import mixture\n",
    "import matplotlib as mpl\n",
    "from matplotlib.figure import Figure\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from scipy import linalg, stats\n",
    "from scipy.spatial import distance\n",
    "from scipy.stats import multivariate_normal\n",
    "import pickle\n",
    "from glob import glob\n",
    "import mne\n",
    "import logging\n",
    "from logging import getLogger, StreamHandler, FileHandler, Formatter\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60869882",
   "metadata": {},
   "outputs": [],
   "source": [
    "FASTER2_NAME = 'FASTER2 version 0.4.1'\n",
    "STAGE_LABELS = ['Wake', 'REM', 'NREM']\n",
    "XLABEL = 'Total low-freq. log-powers'\n",
    "YLABEL = 'Total high-freq. log-powers'\n",
    "ZLABEL = 'REM metric'\n",
    "SCATTER_PLOT_FIG_WIDTH = 6   # inch\n",
    "SCATTER_PLOT_FIG_HEIGHT = 6  # inch\n",
    "FIG_DPI = 100  # dot per inch\n",
    "COLOR_WAKE = '#DC267F'\n",
    "COLOR_NREM = '#648FFF'\n",
    "COLOR_REM = '#FFB000'\n",
    "COLOR_LIGHT = '#FFD700'  # 'gold'\n",
    "COLOR_DARK = '#696969'  # 'dimgray'\n",
    "COLOR_DARKLIGHT = 'lightgray'  # light hours in DD condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6954fb85",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomedGHMM(hmm.GaussianHMM):\n",
    "    def __init__(self, n_components=1, covariance_type='diag',\n",
    "                 min_covar=1e-3,\n",
    "                 startprob_prior=1.0, transmat_prior=1.0,\n",
    "                 means_prior=0, means_weight=0,\n",
    "                 covars_prior=1e-2, covars_weight=1,\n",
    "                 algorithm=\"viterbi\", random_state=None,\n",
    "                 n_iter=10, tol=1e-2, verbose=False,\n",
    "                 params=\"stmc\", init_params=\"stmc\"):\n",
    "        super().__init__(n_components, covariance_type,\n",
    "                         min_covar, startprob_prior, transmat_prior,\n",
    "                         means_prior, means_weight,\n",
    "                         covars_prior, covars_weight,\n",
    "                         algorithm, random_state,\n",
    "                         n_iter, tol, verbose,\n",
    "                         params, init_params)\n",
    "        self.wr_boundary = None\n",
    "        self.nr_boundary = None\n",
    "        self.max_rem_ax = None\n",
    "\n",
    "    def set_wr_boundary(self, wr_boundary):\n",
    "        # Wake/REM boundary. REM cluster cannot grow below this boundary\n",
    "        self.wr_boundary = wr_boundary\n",
    "\n",
    "    def set_nr_boundary(self, nr_boundary):\n",
    "        # NREM/REM boundary. REM cluster cannot grow beyond this boundary\n",
    "        self.nr_boundary = nr_boundary\n",
    "\n",
    "    def set_max_rem_ax(self, max_rem_ax_len):\n",
    "        # maximum length of REM's principal axis\n",
    "        self.max_rem_ax = max_rem_ax_len\n",
    "\n",
    "    def _confine_REM_in_boundary(self, rem_mean, rem_cov):\n",
    "        \"\"\" By definition, REM cluster is not likely z (i.e. REM-metric)<REM_floor and\n",
    "        x (i.e. low-freq power)>0.\n",
    "        This function focuses on the ellipsoid that represents the 95% confidence area\n",
    "        of REM cluster. If this function finds any principal axis of the ellipsoid\n",
    "        penetrating the REM floor or the NREM wall (i.e. the end-point of the principal\n",
    "        axis at z<REM_floor or x>0), it shrinks the length of the axis to the point on\n",
    "        the constraints.\n",
    "        \"\"\"\n",
    "\n",
    "        w, v = linalg.eigh(rem_cov)\n",
    "        # all eigenvalues must be positive\n",
    "        if np.any(w <= 0):\n",
    "            raise ValueError('Invalid_REM_Cluster')\n",
    "\n",
    "        w = 2 * np.sqrt(w)  # 95% confidence (2SD) area\n",
    "\n",
    "        # confine above REM floor\n",
    "        prn_ax = v@np.diag(w)  # 3x3 matrix: each column is the principal axis\n",
    "        for i in range(3):\n",
    "            arr_hd = rem_mean + prn_ax[:, i]  # the arrow head from the mean\n",
    "            # the negative arrow head from the mean\n",
    "            narr_hd = rem_mean - prn_ax[:, i]\n",
    "            if arr_hd[2] < self.wr_boundary:\n",
    "                sr = (rem_mean[2] - self.wr_boundary) / \\\n",
    "                    (rem_mean[2] - arr_hd[2])  # shrink ratio\n",
    "            elif narr_hd[2] < self.wr_boundary:\n",
    "                sr = (rem_mean[2] - self.wr_boundary)/(rem_mean[2] - narr_hd[2])\n",
    "            else:\n",
    "                sr = 1\n",
    "            w[i] = w[i] * sr\n",
    "        \n",
    "        # confine the REM cluster within negative low-freq and above the diagonal line\n",
    "        prn_ax = v@np.diag(w)  # 3x3 matrix: each column is the principal axis\n",
    "        for i in range(3):\n",
    "            arr_hd = rem_mean + prn_ax[:, i] # the arrow head from the mean\n",
    "            narr_hd = rem_mean - prn_ax[:, i] # the negative arrow head from the mean\n",
    "            \n",
    "            # condition 1: negative low-freq and BELOW the diagonal line\n",
    "            if arr_hd[0] > self.nr_boundary and arr_hd[1] < arr_hd[0]:\n",
    "                # condition 2: if positive high-freq > 0 then allow to grow onto the diagonal line\n",
    "                if arr_hd[1] > 0:\n",
    "                    sr = self._shrink_ratio(arr_hd, rem_mean)\n",
    "                # Otherwise (negative high-freq) then only allow to reach onto the y-axis. \n",
    "                else: \n",
    "                    sr = (self.nr_boundary - rem_mean[0])/(arr_hd[0] - rem_mean[0]) # shrink ratio\n",
    "            elif narr_hd[0] > self.nr_boundary and narr_hd[1] < narr_hd[0]:\n",
    "                if narr_hd[1] > 0:\n",
    "                    sr = self._shrink_ratio(narr_hd, rem_mean)\n",
    "                else: \n",
    "                    sr = (self.nr_boundary - rem_mean[0])/(narr_hd[0] - rem_mean[0]) # shrink ratio\n",
    "            else:\n",
    "                sr = 1\n",
    "            w[i] = w[i] * sr\n",
    "\n",
    "        # confine the length of principal axes\n",
    "        prn_ax = v@np.diag(w/2)  # half w because it was doubled in the previous process\n",
    "        prn_ax_len = np.sqrt(np.diag(prn_ax.T@prn_ax)) # lengths of principal axes\n",
    "        for i in range(3):\n",
    "            if prn_ax_len[i] > self.max_rem_ax:\n",
    "                sr = self.max_rem_ax / prn_ax_len[i]\n",
    "            else:\n",
    "                sr = 1\n",
    "            w[i] = w[i] * sr\n",
    "        \n",
    "        cov_updated = v@np.diag((w/2)**2)@v.T\n",
    "\n",
    "        return cov_updated\n",
    "\n",
    "\n",
    "    def _confine_Wake_in_boundary(self, wake_mean, wake_cov):\n",
    "        \"\"\" By definition, Wake cluster is not likely to cross the diagonal line.\n",
    "        This function focuses on the ellipsoid that represents the 95% confidence area\n",
    "        of Wake cluster. If this function finds any principal axis of the ellipsoid\n",
    "        penetrating the diagonal line (i.e. the end-point of the principal\n",
    "        axis is in the area y < x), it shrinks the length of the axis to the point on\n",
    "        the constraints.\n",
    "        \"\"\"\n",
    "\n",
    "        w, v = linalg.eigh(wake_cov)\n",
    "        # all eigenvalues must be positive\n",
    "        if np.any(w <= 0):\n",
    "            raise ValueError('Invalid_Wake_Cluster')\n",
    "\n",
    "        w = 2 * np.sqrt(w)  # 95% confidence (2SD) area\n",
    "        prn_ax = v@np.diag(w)  # 3x3 matrix: each column is the principal axis\n",
    "        # confine above diagonal line\n",
    "        for i in range(3):\n",
    "            arr_hd = wake_mean + prn_ax[:, i]  # the arrow head from the mean\n",
    "            # the negative arrow head from the mean\n",
    "            narr_hd = wake_mean - prn_ax[:, i]\n",
    "            if arr_hd[1] < arr_hd[0]:\n",
    "                sr = self._shrink_ratio(arr_hd, wake_mean)\n",
    "            elif narr_hd[1] < narr_hd[0]:\n",
    "                sr = self._shrink_ratio(narr_hd, wake_mean)\n",
    "            else:\n",
    "                sr = 1\n",
    "            w[i] = w[i] * sr\n",
    "\n",
    "\n",
    "        cov_updated = v@np.diag((w/2)**2)@v.T\n",
    "\n",
    "        return cov_updated\n",
    "\n",
    "    \n",
    "    def _confine_NREM_in_boundary(self, nrem_mean, nrem_cov):\n",
    "        \"\"\" By definition, NREM cluster is not likely to cross the diagonal line.\n",
    "        This function focuses on the ellipsoid that represents the 95% confidence area\n",
    "        of NREM cluster. If this function finds any principal axis of the ellipsoid\n",
    "        penetrating the diagonal line (i.e. the end-point of the principal\n",
    "        axis is in the area y > x), it shrinks the length of the axis to the point on\n",
    "        the constraints.\n",
    "        \"\"\"\n",
    "\n",
    "        w, v = linalg.eigh(nrem_cov)\n",
    "        # all eigenvalues must be positive\n",
    "        if np.any(w <= 0):\n",
    "            raise ValueError('Invalid_NREM_Cluster')\n",
    "\n",
    "        w = 2 * np.sqrt(w)  # 95% confidence (2SD) area\n",
    "        prn_ax = v@np.diag(w)  # 3x3 matrix: each column is the principal axis\n",
    "\n",
    "        # confine above diagonal line\n",
    "        for i in range(3):\n",
    "            arr_hd = nrem_mean + prn_ax[:, i]  # the arrow head from the mean\n",
    "            # the negative arrow head from the mean\n",
    "            narr_hd = nrem_mean - prn_ax[:, i]\n",
    "            if arr_hd[1] > arr_hd[0]:\n",
    "                sr = self._shrink_ratio(arr_hd, nrem_mean)\n",
    "            elif narr_hd[1] > narr_hd[0]:\n",
    "                sr = self._shrink_ratio(narr_hd, nrem_mean)\n",
    "            else:\n",
    "                sr = 1\n",
    "            w[i] = w[i] * sr\n",
    "\n",
    "\n",
    "        cov_updated = v@np.diag((w/2)**2)@v.T\n",
    "\n",
    "        return cov_updated\n",
    " \n",
    "\n",
    "    def _shrink_ratio(self, arr_hd, mn):\n",
    "        r = (arr_hd[1] - mn[1])/(arr_hd[0]-mn[0])\n",
    "        x_on_diag = (mn[1] - r*mn[0])/(1-r)\n",
    "        sr = (x_on_diag - mn[0])/(arr_hd[0] - mn[0])\n",
    "        return sr\n",
    "\n",
    "\n",
    "    #pylint: disable = redefined-outer-name\n",
    "    def _do_mstep(self, stats):\n",
    "        # pylint: disable = attribute-defined-outside-init\n",
    "        ghmm_stats = stats\n",
    "        # pylint: disable = protected-access\n",
    "        base._BaseHMM._do_mstep(self, ghmm_stats)\n",
    "        means_prior = self.means_prior\n",
    "        means_weight = self.means_weight\n",
    "\n",
    "        denom = ghmm_stats['post'][:, np.newaxis]\n",
    "        if 'm' in self.params:\n",
    "            self.means_ = ((means_weight * means_prior + ghmm_stats['obs'])\n",
    "                           / (means_weight + denom))\n",
    " \n",
    "        if 'c' in self.params:\n",
    "            covars_prior = self.covars_prior\n",
    "            covars_weight = self.covars_weight\n",
    "            meandiff = self.means_ - means_prior\n",
    "\n",
    "            if self.covariance_type in ('spherical', 'diag'):\n",
    "                cv_num = (means_weight * meandiff**2\n",
    "                          + ghmm_stats['obs**2']\n",
    "                          - 2 * self.means_ * ghmm_stats['obs']\n",
    "                          + self.means_**2 * denom)\n",
    "                cv_den = max(covars_weight - 1, 0) + denom\n",
    "                self._covars_ = \\\n",
    "                    (covars_prior + cv_num) / np.maximum(cv_den, 1e-5)\n",
    "                if self.covariance_type == 'spherical':\n",
    "                    self._covars_ = np.tile(\n",
    "                        self._covars_.mean(1)[:, np.newaxis],\n",
    "                        (1, self._covars_.shape[1]))\n",
    "            elif self.covariance_type in ('tied', 'full'):\n",
    "                cv_num = np.empty((self.n_components, self.n_features,\n",
    "                                   self.n_features))\n",
    "                for c in range(self.n_components):\n",
    "                    obsmean = np.outer(ghmm_stats['obs'][c], self.means_[c])\n",
    "\n",
    "                    cv_num[c] = (means_weight * np.outer(meandiff[c],\n",
    "                                                         meandiff[c])\n",
    "                                 + ghmm_stats['obs*obs.T'][c]\n",
    "                                 - obsmean - obsmean.T\n",
    "                                 + np.outer(self.means_[c], self.means_[c])\n",
    "                                 * ghmm_stats['post'][c])\n",
    "                cvweight = max(covars_weight - self.n_features, 0)\n",
    "                if self.covariance_type == 'tied':\n",
    "                    self._covars_ = ((covars_prior + cv_num.sum(axis=0)) /\n",
    "                                     (cvweight + ghmm_stats['post'].sum()))\n",
    "                elif self.covariance_type == 'full':\n",
    "                    #covars = ((covars_prior + cv_num) /\n",
    "                    #          (cvweight + ghmm_stats['post'][:, None, None]))\n",
    "                    covars = ((covars_prior + cv_num) /\n",
    "                            np.maximum(cvweight + ghmm_stats['post'][:, None, None], 1e-6))\n",
    "                    covars = np.nan_to_num(covars, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "                    confined_rem_cov = self._confine_REM_in_boundary(\n",
    "                        self.means_[1], covars[1])\n",
    "                    confined_wake_cov = self._confine_Wake_in_boundary(\n",
    "                        self.means_[0], covars[0])\n",
    "                    confined_nrem_cov = self._confine_NREM_in_boundary(\n",
    "                        self.means_[2], covars[2])\n",
    "                    self._covars_ = np.array(\n",
    "                        [confined_wake_cov, confined_rem_cov, confined_nrem_cov])\n",
    "\n",
    "\n",
    "def initialize_logger(log_file):\n",
    "    logger = getLogger(FASTER2_NAME)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "\n",
    "    file_handler = FileHandler(log_file)\n",
    "    stream_handler = StreamHandler()\n",
    "\n",
    "    file_handler.setLevel(logging.DEBUG)\n",
    "    stream_handler.setLevel(logging.NOTSET)\n",
    "    handler_formatter = Formatter('%(message)s')\n",
    "    file_handler.setFormatter(handler_formatter)\n",
    "    stream_handler.setFormatter(handler_formatter)\n",
    "\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(stream_handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "\n",
    "def print_log(msg):\n",
    "    if 'log' in globals():\n",
    "        log.debug(msg)\n",
    "    else:\n",
    "        print(msg)\n",
    "\n",
    "\n",
    "def print_log_exception(msg):\n",
    "    if 'log' in globals():\n",
    "        log.exception(msg)\n",
    "    else:\n",
    "        print(msg)\n",
    "\n",
    "\n",
    "def read_mouse_info(data_dir):\n",
    "    \"\"\"This function reads the mouse.info.csv file\n",
    "    and returns a DataFrame with fixed column names.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): A path to the data directory that contains the mouse.info.csv\n",
    "\n",
    "\n",
    "        The data directory should include two information files:\n",
    "        1. exp.info.csv,\n",
    "        2. mouse.info.csv,\n",
    "        and one directory named \"raw\" that contains all EEG/EMG data to be processed\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A dataframe with a fixed column names\n",
    "    \"\"\"\n",
    "\n",
    "    filepath = os.path.join(data_dir, \"mouse.info.csv\")\n",
    "\n",
    "    try:\n",
    "        codename = et.encode_lookup(filepath)\n",
    "    except LookupError as e:\n",
    "        print_log(e)\n",
    "        exit(1)\n",
    "\n",
    "    csv_df = pd.read_csv(filepath,\n",
    "                         engine=\"python\",\n",
    "                         dtype={'Device label': str, 'Mouse group': str,\n",
    "                                'Mouse ID': str, 'DOB': str, 'Stats report': str, 'Note': str},\n",
    "                         names=[\"Device label\", \"Mouse group\",\n",
    "                                \"Mouse ID\", \"DOB\", \"Stats report\", \"Note\"],\n",
    "                         skiprows=1,\n",
    "                         header=None,\n",
    "                         skipinitialspace=True,\n",
    "                         encoding=codename)\n",
    "\n",
    "    return csv_df\n",
    "\n",
    "\n",
    "# def read_exp_info(data_dir):\n",
    "#     \"\"\"This function reads the exp.info.csv file\n",
    "#     and returns a DataFrame with fixed column names.\n",
    "\n",
    "#     Args:\n",
    "#         data_dir (str): A path to the data directory that contains the exp.info.csv\n",
    "\n",
    "#     Returns:\n",
    "#         DataFrame: A DataFrame with a fixed column names\n",
    "#     \"\"\"\n",
    "\n",
    "#     filepath = os.path.join(data_dir, \"exp.info.csv\")\n",
    "\n",
    "#     csv_df = pd.read_csv(filepath,\n",
    "#                          engine=\"python\",\n",
    "#                          names=[\"Experiment label\", \"Rack label\",\n",
    "#                                 \"Start datetime\", \"End datetime\", \"Sampling freq\"],\n",
    "#                          skiprows=1,\n",
    "#                          header=None)\n",
    "\n",
    "#     return csv_df\n",
    "\n",
    "\n",
    "# def find_edf_files(data_dir):\n",
    "#     \"\"\"returns list of edf files in the directory\n",
    "\n",
    "#     Args:\n",
    "#         data_dir (str): A path to the data directory\n",
    "\n",
    "#     Returns:\n",
    "#         [list]: A list returned by glob()\n",
    "#     \"\"\"\n",
    "#     return glob(os.path.join(data_dir, '*.edf'))\n",
    "\n",
    "\n",
    "def read_voltage_matrices(data_dir, device_id, sample_freq, epoch_len_sec, epoch_num,\n",
    "                          start_datetime=None):\n",
    "    \"\"\" This function reads data files of EEG and EMG, then returns matrices\n",
    "    in the shape of (epochs, signals).\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): a path to the dirctory that contains either dsi.txt/, pkl/ directory,\n",
    "        or an EDF file.\n",
    "        device_id (str): a transmitter ID (e.g., ID47476) or channel ID (e.g., 09).\n",
    "        sample_freq (int): sampling frequency\n",
    "        epoch_len_sec (int): the length of an epoch in seconds\n",
    "        epoch_num (int): the number of epochs to be read.\n",
    "        start_datetime (datetime): start datetime of the analysis (used only for EDF file and\n",
    "        dsi.txt).\n",
    "\n",
    "    Returns:\n",
    "        (np.array(2), np.arrray(2), bool): a pair of voltage 2D matrices in a tuple\n",
    "        and a switch to tell if there was pickled data.\n",
    "\n",
    "    Note:\n",
    "        This function looks into the data_dir/ and first try to read pkl files. If pkl files\n",
    "        are not found, it tries to read an EDF file. If the EDF file is also not found, it\n",
    "        tries to read dsi.txt files.\n",
    "    \"\"\"\n",
    "\n",
    "    if os.path.exists(os.path.join(data_dir, 'pkl', f'{device_id}_EEG.pkl')):\n",
    "        # if it exists, read the pkl file\n",
    "        not_yet_pickled = False\n",
    "        # Try to read pickled data\n",
    "        pkl_path = os.path.join(data_dir, 'pkl', f'{device_id}_EEG.pkl')\n",
    "        with open(pkl_path, 'rb') as pkl:\n",
    "            print_log(f'Reading {pkl_path}')\n",
    "            eeg_vm = pickle.load(pkl)\n",
    "\n",
    "        pkl_path = os.path.join(data_dir, 'pkl', f'{device_id}_EMG.pkl')\n",
    "        with open(pkl_path, 'rb') as pkl:\n",
    "            print_log(f'Reading {pkl_path}')\n",
    "            emg_vm = pickle.load(pkl)\n",
    "\n",
    "    elif len(find_edf_files(data_dir)) > 0:\n",
    "        # try to read EDF file\n",
    "        not_yet_pickled = True\n",
    "        # read EDF file\n",
    "        edf_file = find_edf_files(data_dir)\n",
    "        if len(edf_file) != 1:\n",
    "            raise FileNotFoundError(\n",
    "                f'Too many EDF files were found:{edf_file}. '\n",
    "                'FASTER2 assumes there is only one file.')\n",
    "        edf_file = edf_file[0]\n",
    "\n",
    "        raw = mne.io.read_raw_edf(edf_file)\n",
    "        measurement_start_datetime = datetime.utcfromtimestamp(\n",
    "            raw.info['meas_date'][0]) + timedelta(microseconds=raw.info['meas_date'][1])\n",
    "        try:\n",
    "            if isinstance(start_datetime, datetime) and (measurement_start_datetime < start_datetime):\n",
    "                start_offset_sec = (\n",
    "                    start_datetime - measurement_start_datetime).total_seconds()\n",
    "                end_offset_sec = start_offset_sec + epoch_num * epoch_len_sec\n",
    "                bidx = (raw.times >= start_offset_sec) & (\n",
    "                    raw.times < end_offset_sec)\n",
    "                start_slice = np.where(bidx)[0][0]\n",
    "                end_slice = np.where(bidx)[0][-1]+1\n",
    "                eeg = raw.get_data(f'EEG{device_id}',\n",
    "                                   start_slice, end_slice)[0]\n",
    "                emg = raw.get_data(f'EMG{device_id}',\n",
    "                                   start_slice, end_slice)[0]\n",
    "            else:\n",
    "                eeg = raw.get_data(f'EEG{device_id}')[0]\n",
    "                emg = raw.get_data(f'EMG{device_id}')[0]\n",
    "        except ValueError:\n",
    "            print_log(f'Failed to extract the data of \"{device_id}\" from {edf_file}. '\n",
    "                      f'Check the channel name: \"EEG/EMG{device_id}\" is in the EDF file.')\n",
    "            raise\n",
    "        raw.close()\n",
    "        try:\n",
    "            eeg_vm = eeg.reshape(-1, epoch_len_sec * sample_freq)\n",
    "            emg_vm = emg.reshape(-1, epoch_len_sec * sample_freq)\n",
    "        except ValueError:\n",
    "            print_log(f'Failed to extract {epoch_num} epochs from {edf_file}. '\n",
    "                      'Check the validity of the epoch number, start datetime, '\n",
    "                      'and sampling frequency.')\n",
    "            raise\n",
    "    elif os.path.exists(os.path.join(data_dir, 'dsi.txt')):\n",
    "        # try to read dsi.txt\n",
    "        not_yet_pickled = True\n",
    "        try:\n",
    "            dsi_reader_eeg = et.DSI_TXT_Reader(os.path.join(data_dir, 'dsi.txt/'),\n",
    "                                               f'{device_id}', 'EEG',\n",
    "                                               sample_freq=sample_freq)\n",
    "            dsi_reader_emg = et.DSI_TXT_Reader(os.path.join(data_dir, 'dsi.txt/'),\n",
    "                                               f'{device_id}', 'EMG',\n",
    "                                               sample_freq=sample_freq)\n",
    "            if isinstance(start_datetime, datetime):\n",
    "                end_datetime = start_datetime + \\\n",
    "                    timedelta(seconds=epoch_len_sec*epoch_num)\n",
    "                eeg_df = dsi_reader_eeg.read_epochs_by_datetime(\n",
    "                    start_datetime, end_datetime)\n",
    "                emg_df = dsi_reader_emg.read_epochs_by_datetime(\n",
    "                    start_datetime, end_datetime)\n",
    "            else:\n",
    "                eeg_df = dsi_reader_eeg.read_epochs(1, epoch_num)\n",
    "                emg_df = dsi_reader_emg.read_epochs(1, epoch_num)\n",
    "            eeg_vm = eeg_df.value.values.reshape(-1,\n",
    "                                                 epoch_len_sec * sample_freq)\n",
    "            emg_vm = emg_df.value.values.reshape(-1,\n",
    "                                                 epoch_len_sec * sample_freq)\n",
    "        except FileNotFoundError:\n",
    "            print_log(\n",
    "                f'The dsi.txt file for {device_id} was not found in {data_dir}.')\n",
    "            raise\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            f'Data file was not found for device {device_id} in {data_dir}.')\n",
    "\n",
    "    expected_shape = (epoch_num, sample_freq * epoch_len_sec)\n",
    "    if (eeg_vm.shape != expected_shape) or (emg_vm.shape != expected_shape):\n",
    "        raise ValueError(f'Unexpected shape of matrices EEG:{eeg_vm.shape} or EMG:{emg_vm.shape}. '\n",
    "                         f'Expected shape is {expected_shape}. Check the validity of '\n",
    "                         'the data files or configurations '\n",
    "                         'such as the epoch number and the sampling frequency.')\n",
    "\n",
    "    return (eeg_vm, emg_vm, not_yet_pickled)\n",
    "\n",
    "\n",
    "# def interpret_datetimestr(datetime_str):\n",
    "#     \"\"\" Find a datetime string and convert it to a datatime object\n",
    "#     allowing some variant forms\n",
    "\n",
    "#     Args:\n",
    "#         datetime_str (string): a string containing datetime\n",
    "\n",
    "#     Returns:\n",
    "#         a datetime object\n",
    "\n",
    "#     Raises:\n",
    "#         ValueError: raised when interpretation is failed\n",
    "#     \"\"\"\n",
    "\n",
    "#     datestr_patterns = [r'(\\d{4})(\\d{2})(\\d{2})',\n",
    "#                         r'(\\d{4})/(\\d{1,2})/(\\d{1,2})',\n",
    "#                         r'(\\d{4})-(\\d{1,2})-(\\d{1,2})']\n",
    "\n",
    "#     timestr_patterns = [r'(\\d{2})(\\d{2})(\\d{2})',\n",
    "#                         r'(\\d{1,2}):(\\d{1,2}):(\\d{1,2})',\n",
    "#                         r'(\\d{1,2})-(\\d{1,2})-(\\d{1,2})']\n",
    "\n",
    "#     datetime_obj = None\n",
    "#     for pat in datestr_patterns:\n",
    "#         matched = re.search(pat, datetime_str)\n",
    "#         if matched:\n",
    "#             year = int(matched.group(1))\n",
    "#             month = int(matched.group(2))\n",
    "#             day = int(matched.group(3))\n",
    "#             datetime_str = re.sub(pat, '', datetime_str)\n",
    "\n",
    "#             for pat_time in timestr_patterns:\n",
    "#                 matched_time = re.search(pat_time, datetime_str)\n",
    "#                 if matched_time:\n",
    "#                     hour = int(matched_time.group(1))\n",
    "#                     minuite = int(matched_time.group(2))\n",
    "#                     second = int(matched_time.group(3))\n",
    "#                     datetime_obj = datetime(year, month, day,\n",
    "#                                             hour, minuite, second)\n",
    "#                     break\n",
    "#             if not matched_time:\n",
    "#                 datetime_obj = datetime(year, month, day)\n",
    "#     if not datetime_obj:\n",
    "#         raise ValueError(\n",
    "#             'failed to interpret datetime string \\'{}\\''.format(datetime_str))\n",
    "\n",
    "#     return datetime_obj\n",
    "\n",
    "\n",
    "# def interpret_exp_info(exp_info_df, epoch_len_sec):\n",
    "#     try:\n",
    "#         start_datetime_str = exp_info_df['Start datetime'].values[0]\n",
    "#         end_datetime_str = exp_info_df['End datetime'].values[0]\n",
    "#         sample_freq = exp_info_df['Sampling freq'].values[0]\n",
    "#         exp_label = exp_info_df['Experiment label'].values[0]\n",
    "#         rack_label = exp_info_df['Rack label'].values[0]\n",
    "#     except KeyError as e:\n",
    "#         print_log(\n",
    "#             f'Failed to parse the column: {e} in exp.info.csv. Check the headers.')\n",
    "#         exit(1)\n",
    "\n",
    "#     start_datetime = interpret_datetimestr(start_datetime_str)\n",
    "#     end_datetime = interpret_datetimestr(end_datetime_str)\n",
    "\n",
    "#     epoch_num = int(\n",
    "#         (end_datetime - start_datetime).total_seconds() / epoch_len_sec)\n",
    "\n",
    "#     return (epoch_num, sample_freq, exp_label, rack_label, start_datetime, end_datetime)\n",
    "\n",
    "\n",
    "def psd(y, n_fft, sample_freq):\n",
    "    return signal.welch(y, nfft=n_fft, fs=sample_freq)[1][0:129]\n",
    "\n",
    "\n",
    "def plot_hist_on_separation_axis(path2figures, d, means, covars, weights, draw_pdf_plot=False):\n",
    "\n",
    "    if means[0] > means[1]:\n",
    "        # reverse the order\n",
    "        means = means[::-1]\n",
    "        covars = covars[::-1]\n",
    "        weights = weights[::-1]\n",
    "\n",
    "    d_axis = np.arange(-20, 20)\n",
    "\n",
    "    fig = Figure(figsize=(SCATTER_PLOT_FIG_WIDTH,\n",
    "                          SCATTER_PLOT_FIG_HEIGHT), dpi=FIG_DPI, facecolor='w')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xlim(-20, 20)\n",
    "    ax.set_ylim(0, 0.1)\n",
    "\n",
    "    ax.hist(d, bins=100, density=True)\n",
    "    ax.plot(d_axis, weights[0]*stats.norm.pdf(d_axis,\n",
    "                                              means[0], np.sqrt(covars[0])).ravel(), c=COLOR_WAKE)\n",
    "    ax.plot(d_axis, weights[1]*stats.norm.pdf(d_axis,\n",
    "                                              means[1], np.sqrt(covars[1])).ravel(), c=COLOR_NREM)\n",
    "    ax.axvline(x=means[0], color='black', dashes=[2, 2])\n",
    "    ax.axvline(x=means[1], color='black', dashes=[2, 2])\n",
    "    ax.axvline(x=np.mean(means), color='black')\n",
    "\n",
    "    ax.set_xlabel('', fontsize=10)\n",
    "    ax.set_ylabel('', fontsize=10)\n",
    "\n",
    "    _savefig(path2figures, 'histogram_on_separation_axis', fig, draw_pdf_plot)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_scatter2D(points_2D, classes, means, covariances, colors, xlabel, ylabel, diag_line=False):\n",
    "    fig = Figure(figsize=(SCATTER_PLOT_FIG_WIDTH,\n",
    "                          SCATTER_PLOT_FIG_HEIGHT), dpi=FIG_DPI, facecolor='w')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xlim(-20, 20)\n",
    "    ax.set_ylim(-20, 20)\n",
    "\n",
    "    for i, color in enumerate(colors):\n",
    "\n",
    "        ax.scatter(points_2D[classes == i, 0],\n",
    "                   points_2D[classes == i, 1], .01, color=color)\n",
    "\n",
    "        # Plot an ellipse to show the Gaussian component\n",
    "        if (len(means) > i and len(covariances) > i):\n",
    "            mean = means[i]\n",
    "            covar = covariances[i]\n",
    "            w, v = linalg.eigh(covar)\n",
    "            w = 4. * np.sqrt(w)  # 95% confidence (2SD) area (2*radius)\n",
    "            angle = np.arctan(v[1, 0] / v[0, 0])\n",
    "            angle = 180. * angle / np.pi  # convert to degrees\n",
    "            #ell = mpl.patches.Ellipse(\n",
    "            #    mean, w[0], w[1], 180. + angle, facecolor='none', edgecolor=color)\n",
    "            ell = mpl.patches.Ellipse(\n",
    "                xy=mean, width=w[0], height=w[1], angle=180. + angle, facecolor='none', edgecolor=color)\n",
    "            ax.add_patch(ell)\n",
    "    if diag_line == True:\n",
    "        ax.plot([-20, 20], [-20, 20], color='gray', linewidth=0.7)\n",
    "    ax.set_xlabel(xlabel, fontsize=10)\n",
    "    ax.set_ylabel(ylabel, fontsize=10)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def pickle_voltage_matrices(eeg_vm, emg_vm, data_dir, device_id):\n",
    "    \"\"\" To save time for reading CSV files, pickle the voltage matrices\n",
    "    in pickle files.\n",
    "    \n",
    "    Args:\n",
    "        eeg_vm (np.array): voltage matrix for EEG data\n",
    "        emg_vm (np.array): voltage matrix for EMG data\n",
    "        data_dir (str):  path to the directory of pickled data (pkl/)\n",
    "        device_id (str): a string to identify the recording device (e.g. ID47467)\n",
    "\"\"\"\n",
    "    pickle_dir = os.path.join(data_dir, 'pkl/')\n",
    "    os.makedirs(pickle_dir, exist_ok=True)\n",
    "\n",
    "    # save EEG\n",
    "    pkl_path = os.path.join(pickle_dir, f'{device_id}_EEG.pkl')\n",
    "    if os.path.exists(pkl_path):\n",
    "        print_log(f'File already exists. Nothing to be done. {pkl_path}')\n",
    "    else:\n",
    "        with open(pkl_path, 'wb') as pkl:\n",
    "            print_log(f'Saving the voltage matrix into {pkl_path}')\n",
    "            pickle.dump(eeg_vm, pkl)\n",
    "\n",
    "    # save EMG\n",
    "    pkl_path = os.path.join(pickle_dir, f'{device_id}_EMG.pkl')\n",
    "    if os.path.exists(pkl_path):\n",
    "        print_log(f'File already exists. Nothing to be done. {pkl_path} ')\n",
    "    else:\n",
    "        with open(pkl_path, 'wb') as pkl:\n",
    "            print_log(f'Saving the voltage matrix into {pkl_path}')\n",
    "            pickle.dump(emg_vm, pkl)\n",
    "\n",
    "\n",
    "def pickle_powerspec_matrices(spec_norm_eeg, spec_norm_emg, result_dir_path, device_id):\n",
    "    \"\"\" pickles the power spectrum density matrices for subsequent analyses\n",
    "\n",
    "    Args:\n",
    "        spec_norm_eeg (dict): a dict returned by spectrum_normalize() for EEG data\n",
    "        spec_norm_emg (dict): a dict returned by spectrum_normalize() for EMG data\n",
    "        bidx_unknown (np.array): an array of the boolean index\n",
    "        result_dir_path (str):  path to the directory of the pickled data (PSD/)\n",
    "        device_id (str): a string to identify the recording device (e.g. ID47467)\n",
    "    \"\"\"\n",
    "    pickle_dir = os.path.join(result_dir_path, 'PSD/')\n",
    "    os.makedirs(pickle_dir, exist_ok=True)\n",
    "\n",
    "    print_log(f'Saving PSD files')\n",
    "\n",
    "    # save EEG PSD\n",
    "    pkl_path = os.path.join(pickle_dir, f'{device_id}_EEG_PSD.pkl')\n",
    "    #if os.path.exists(pkl_path):\n",
    "    #    print_log(f'File already exists: {pkl_path}')\n",
    "    #else:\n",
    "    with open(pkl_path, 'wb') as pkl:\n",
    "        print_log(f'Saving the EEG PSD matrix into {pkl_path}')\n",
    "        pickle.dump(spec_norm_eeg, pkl)\n",
    "\n",
    "    # save EMG PSD\n",
    "    pkl_path = os.path.join(pickle_dir, f'{device_id}_EMG_PSD.pkl')\n",
    "    #if os.path.exists(pkl_path):\n",
    "    #    print_log(f'File already exists: {pkl_path} ')\n",
    "    #else:\n",
    "    with open(pkl_path, 'wb') as pkl:\n",
    "        print_log(f'Saving the EMG PSD matrix into {pkl_path}')\n",
    "        pickle.dump(spec_norm_emg, pkl)\n",
    "\n",
    "\n",
    "def pickle_cluster_params(means2, covars2, c_means, c_covars, result_dir_path, device_id):\n",
    "    \"\"\" pickles the cluster parameters\n",
    "    \n",
    "    Args:\n",
    "        means2 (np.array(2,2)): a mean matrix of 2 stage-clusters\n",
    "        covars2 (np.array(2,2,2)): a covariance matrix of 2 stage-clusters\n",
    "        c_means (np.array(3,3)):  a mean matrix of 3 stage-clusters\n",
    "        c_covars (np.array(3,3,3)): a covariance matrix of 3 stage-clusters\n",
    "    \"\"\"\n",
    "    pickle_dir = os.path.join(result_dir_path, 'cluster_params/')\n",
    "    os.makedirs(pickle_dir, exist_ok=True)\n",
    "\n",
    "    # save\n",
    "    pkl_path = os.path.join(pickle_dir, f'{device_id}_cluster_params.pkl')\n",
    "    print_log(f'Saving the cluster parameters into {pkl_path}')\n",
    "    with open(pkl_path, 'wb') as pkl:\n",
    "        pickle.dump({'2stage-means': means2, '2stage-covars': covars2,\n",
    "                     '3stage-means': c_means, '3stage-covars': c_covars}, pkl)\n",
    "\n",
    "def remove_extreme_voltage(y, sample_freq):\n",
    "    \"\"\"An optional function to remove periodic-spike noises such as\n",
    "    heart beat in EMG. Since the spikes are ofhen above 1.64 SD (upper 10%) \n",
    "    within the data region of interest, FASTER2 tries to replace those points with\n",
    "    randam values.\n",
    "    Note: This function is destructive i.e. it changes values of the\n",
    "    given vector.\n",
    "\n",
    "\n",
    "    Args:\n",
    "        y (np.array(1)): a vector of voltages in an epoch\n",
    "        sample_freq (int): the sampling frequency\n",
    "    \"\"\"\n",
    "    vm = y.reshape(-1, sample_freq*2) # 2 sec\n",
    "    for v in vm:\n",
    "        m = np.mean(v)\n",
    "        s = np.std(v)\n",
    "        bidx = (abs(v) - m) > 1.64*s\n",
    "        v[bidx] =  np.random.normal(m, s, np.sum(bidx))\n",
    "\n",
    "\n",
    "def remove_extreme_power(y):\n",
    "    \"\"\"In FASTER2, the spectrum powers are normalized so that the mean and \n",
    "    SD of each frequency power over all epochs become 0 and 1, respectively.  \n",
    "    This function removes extremely high or low powers in the normalized \n",
    "    spectrum by replacing the value with a random number sampled from the \n",
    "    noraml distribution: N(0, 1). \n",
    "    \n",
    "    Args:\n",
    "        y (np.array(1)): a vector of normalized power spectrum\n",
    "    \n",
    "    Returns:\n",
    "        float: The ratio of the replaced exreme values in the given vector.\n",
    "    \"\"\"\n",
    "    n_len = len(y)\n",
    "\n",
    "    bidx = (np.abs(y) > 3)  # extreme means over 3SD\n",
    "    n_extr = np.sum(bidx)\n",
    "\n",
    "    y[bidx] = np.random.normal(0, 1, n_extr)\n",
    "\n",
    "    return n_extr / n_len\n",
    "\n",
    "\n",
    "def spectrum_normalize(voltage_matrix, n_fft, sample_freq):\n",
    "    # power-spectrum normalization of EEG\n",
    "    psd_mat = np.apply_along_axis(lambda y: psd(\n",
    "        y, n_fft, sample_freq), 1, voltage_matrix)\n",
    "    psd_mat = 10*np.log10(psd_mat)  # decibel-like\n",
    "    psd_mean = np.apply_along_axis(np.nanmean, 0, psd_mat)\n",
    "    psd_sd = np.apply_along_axis(np.nanstd, 0, psd_mat)\n",
    "    spec_norm_fac = 1/psd_sd\n",
    "    psd_norm_mat = np.apply_along_axis(lambda y: spec_norm_fac*(y - psd_mean),\n",
    "                                       1,\n",
    "                                       psd_mat)\n",
    "    return {'psd': psd_norm_mat, 'mean': psd_mean, 'norm_fac': spec_norm_fac}\n",
    "\n",
    "\n",
    "def cancel_weight_bias(stage_coord_2D):\n",
    "    # Estimate the center of the two clusters\n",
    "    print_log('Estimate the bias of the two cluster means')\n",
    "    d = stage_coord_2D@np.array([1, -1]).T  # project onto the separation axis\n",
    "    d = d.reshape(-1, 1)\n",
    "    # Two states: active and quiet\n",
    "    gmm = mixture.BayesianGaussianMixture(n_components=2, n_init=10)\n",
    "    gmm.fit(d)\n",
    "    weights = gmm.weights_\n",
    "    means = gmm.means_.flatten()\n",
    "    covars = gmm.covariances_.flatten()\n",
    "\n",
    "    # this is supposed to be zero if weights are completely balanced\n",
    "    bias = np.mean(means[0:2])\n",
    "    s = bias/np.sqrt(2)  # x,y-axis components\n",
    "    print_log(f'Estimated bias: {s}')\n",
    "\n",
    "    stage_coord_2D = stage_coord_2D + [-s, s]\n",
    "\n",
    "    return {'proj_data': d, 'means': means, 'covars': covars, 'weights': weights, 'stage_coord_2D': stage_coord_2D}\n",
    "\n",
    "\n",
    "def classify_active_and_NREM(stage_coord_2D):\n",
    "    # Initialize active/stative(NREM) clusters by Gaussian mixture model ignoring transition probablity\n",
    "    print_log('Initialize active/NREM clusters with the diagonal line')\n",
    "\n",
    "    # projection onto the separation \"line\" (which is perpendicular to the separation \"axis\")\n",
    "    stage_coord_1DD = stage_coord_2D@np.array([1, 1]).T\n",
    "    bidx_over_outliers = stage_coord_1DD > (\n",
    "        np.mean(stage_coord_1DD) + 3*np.std(stage_coord_1DD))\n",
    "    bidx_under_outliers = stage_coord_1DD < (\n",
    "        np.mean(stage_coord_1DD) - 3*np.std(stage_coord_1DD))\n",
    "    bidx_valid = ~(bidx_over_outliers | bidx_under_outliers)\n",
    "\n",
    "    # To estimate clusters, use only epochs projected within the reasonable region on the separation line (<3SD)\n",
    "    def _geo_classifier(coord):\n",
    "        # geometrical classifier (simpl separation by the diagonal line)\n",
    "        if coord[0] - coord[1] > 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    # Means and covariances of the active and NREM clusters\n",
    "    geo_pred = np.array([_geo_classifier(c) for c in stage_coord_2D])\n",
    "    mm_2D = np.array([\n",
    "        np.mean(stage_coord_2D[geo_pred == 0 & bidx_valid], axis=0),\n",
    "        np.mean(stage_coord_2D[geo_pred == 1 & bidx_valid], axis=0),\n",
    "    ])\n",
    "    cc_2D = np.array([\n",
    "        np.cov(stage_coord_2D[geo_pred == 0 & bidx_valid], rowvar=False),\n",
    "        np.cov(stage_coord_2D[geo_pred == 1 & bidx_valid], rowvar=False)\n",
    "    ])\n",
    "\n",
    "    likelihood = np.stack([multivariate_normal.pdf(stage_coord_2D, mean=mm_2D[i], cov=cc_2D[i])\n",
    "                           for i in [0, 1]])\n",
    "    geo_pred_proba = (likelihood / likelihood.sum(axis=0))\n",
    "\n",
    "    return (geo_pred, geo_pred_proba.T, mm_2D, cc_2D)\n",
    "\n",
    "\n",
    "def classify_active_and_NREM_by_GHMM(stage_coord_2D, pred_2D, mm_2D, cc_2D):\n",
    "    # Initialize active/stative(NREM) clusters by Gaussian mixture model ignoring transition probablity\n",
    "    print_log('Classify active/NREM clusters with GHMM')\n",
    "\n",
    "    weights = np.array(\n",
    "        [np.sum(pred_2D == 0), np.sum(pred_2D == 1)])/len(pred_2D)\n",
    "\n",
    "    ghmm_2D = hmm.GaussianHMM(\n",
    "        n_components=2, covariance_type='full', init_params='t', params='tmcs')\n",
    "    ghmm_2D.startprob_ = weights\n",
    "    ghmm_2D.means_ = mm_2D\n",
    "    ghmm_2D.covars_ = cc_2D\n",
    "\n",
    "    ghmm_2D.fit(stage_coord_2D)\n",
    "    ghmm_2D_pred = ghmm_2D.predict(stage_coord_2D)\n",
    "    ghmm_2D_proba = ghmm_2D.predict_proba(stage_coord_2D)\n",
    "    return (ghmm_2D_pred, ghmm_2D_proba, ghmm_2D.means_, ghmm_2D.covars_)\n",
    "\n",
    "\n",
    "def classify_Wake_and_REM(stage_coord_active, rem_floor):\n",
    "    # Classify REM and Wake in the active cluster in the 3D space  (Low freq. x High freq. x REM metric)\n",
    "    print_log('Classify REM and Wake clusters with GMM')\n",
    "\n",
    "    # exclude intermediate points between REM and Wake, and points having substantial sleep_freq power\n",
    "    bidx_wake_rem = ((stage_coord_active[:, 2] > rem_floor) | (\n",
    "        stage_coord_active[:, 2] < 0)) & (stage_coord_active[:, 0] < 0)\n",
    "    stage_coord_wake_rem = stage_coord_active[bidx_wake_rem, :]\n",
    "\n",
    "    # gmm for wake & REM\n",
    "    gmm_wr = mixture.GaussianMixture(n_components=3, n_init=100, means_init=[\n",
    "                                     [-5, 5, -10], [0, 0, 20], [0, 0, 0]])  # Wake, REM, intermediate\n",
    "    gmm_wr.fit(stage_coord_wake_rem)\n",
    "    ww_wr = gmm_wr.weights_\n",
    "    mm_wr = gmm_wr.means_\n",
    "    cc_wr = gmm_wr.covariances_\n",
    "    pred_wr = gmm_wr.predict(stage_coord_active)\n",
    "    pred_wr_proba = gmm_wr.predict_proba(stage_coord_active)\n",
    "\n",
    "    # Treat the intermediate as wake\n",
    "    pred_wr[pred_wr == 2] = 0\n",
    "    pred_wr_proba = np.array([[x[0]+x[2], x[1]] for x in pred_wr_proba])\n",
    "\n",
    "    # The subsequent process uses the Wake and REM clusters\n",
    "    ww_wr = ww_wr[np.r_[0, 1]]\n",
    "    mm_wr = mm_wr[np.r_[0, 1]]\n",
    "    cc_wr = cc_wr[np.r_[0, 1]]\n",
    "\n",
    "    if mm_wr[0, 2] > mm_wr[1, 2]:\n",
    "        # flip the order of clusters to assure the order of indices 0:Wake, 1:REM\n",
    "        mm_wr = np.array([mm_wr[1], mm_wr[0]])\n",
    "        cc_wr = np.array([cc_wr[1], cc_wr[0]])\n",
    "        pred_wr = np.array([0 if x == 1 else 1 for x in pred_wr])\n",
    "        pred_wr_proba = pred_wr_proba[:, np.r_[1, 0]]\n",
    "\n",
    "    return (pred_wr, pred_wr_proba, mm_wr, cc_wr, ww_wr)\n",
    "\n",
    "\n",
    "def classify_three_stages(stage_coord, mm_3D, cc_3D, weights_3c, max_rem_prn_len):\n",
    "    # pylint: disable = attribute-defined-outside-init\n",
    "    # classify REM, Wake, and NREM by Gaussian HMM in the 3D space\n",
    "    print_log('Classify REM, Wake, and NREM by Gaussian HMM')\n",
    "    ghmm_3D = CustomedGHMM(\n",
    "        n_components=3, covariance_type='full', init_params='t', params='ct')\n",
    "    ghmm_3D.startprob_ = weights_3c\n",
    "    ghmm_3D.means_ = mm_3D\n",
    "    ghmm_3D.covars_ = cc_3D\n",
    "    ghmm_3D.set_wr_boundary(0)\n",
    "    ghmm_3D.set_nr_boundary(0)\n",
    "    ghmm_3D.set_max_rem_ax(max_rem_prn_len)\n",
    "\n",
    "    ghmm_3D.fit(stage_coord)\n",
    "    pred_3D = ghmm_3D.predict(stage_coord)\n",
    "    pred_3D_proba = ghmm_3D.predict_proba(stage_coord)\n",
    "    pred_3D_mm = ghmm_3D.means_\n",
    "    pred_3D_cc = ghmm_3D.covars_\n",
    "\n",
    "    return (pred_3D, pred_3D_proba, pred_3D_mm, pred_3D_cc)\n",
    "\n",
    "\n",
    "def classify_two_stages(stage_coord, pred_2D_org, mm_2D_org, cc_2D_org, mm_active, cc_active):\n",
    "    ndata = len(stage_coord)\n",
    "    bidx_active = (pred_2D_org == 0)\n",
    "    # perform GMM to refine active/NREM classification\n",
    "    pred_2D, pred_2D_proba, mm_2D, cc_2D = classify_active_and_NREM_by_GHMM(\n",
    "        stage_coord[:, 0:2], pred_2D_org, mm_2D_org, cc_2D_org)\n",
    "\n",
    "    # construct 3D means and covariances from mm_2D and mm_active with TINY (non-effective) REM cluster\n",
    "    # This non-effective REM cluster is just for convenience of plotting, so has nothing to do with analytical process.\n",
    "    mm_3D = np.vstack([mm_active[0], [0, 0, 100], np.mean(\n",
    "        stage_coord[pred_2D == 1], axis=0)])  # Wake, REM, NREM\n",
    "    cc_3D = np.vstack([[cc_active[0]], [np.diag([0.01, 0.01, 0.01])], [\n",
    "                      np.cov(stage_coord[pred_2D == 1], rowvar=False)]])\n",
    "\n",
    "    # change label of NREM from 1 to 2 so that REM can use label:1\n",
    "    pred_3D = np.array([2 if x == 1 else 0 for x in pred_2D])\n",
    "    idx_active = np.where(bidx_active)[0]\n",
    "    # idx_REMlike = idx_active[bidx_REMlike]\n",
    "    # pred_3D[idx_REMlike] = 1\n",
    "\n",
    "    pred_3D_proba = np.zeros([ndata, 3])\n",
    "    # probability of REM is always zero, but sometimes REM like.\n",
    "    pred_3D_proba[:, np.r_[0, 2]] = pred_2D_proba\n",
    "\n",
    "    return pred_2D, pred_2D_proba, mm_2D, cc_2D, pred_3D, pred_3D_proba, mm_3D, cc_3D\n",
    "\n",
    "\n",
    "def classification_process(stage_coord, rem_floor):\n",
    "    if np.any(np.isnan(stage_coord)) or np.any(np.isinf(stage_coord)):\n",
    "        raise ValueError(f\"Invalid values in stage_coord: {stage_coord}\")\n",
    "    ndata = len(stage_coord)\n",
    "\n",
    "    # 2-stage classification\n",
    "    print(\"classify active and NREM\")\n",
    "    # classify active and NREM clusters on the 2D plane of (Low freq. x High freq.)\n",
    "    pred_2D, pred_2D_proba, mm_2D, cc_2D = classify_active_and_NREM(\n",
    "        stage_coord[:, 0:2])\n",
    "\n",
    "    # Calculate the length of the longest principal axis of the active cluster\n",
    "    w, v = linalg.eigh(cc_2D[0])\n",
    "    w = np.sqrt(w)\n",
    "    prn_ax = v@np.diag(w) # each column is the principal axis\n",
    "    prn_ax_len = np.sqrt(np.diag(prn_ax.T@prn_ax))\n",
    "    max_prn_ax_len = np.max(prn_ax_len)\n",
    "\n",
    "    # Classify REM and Wake in the active cluster in the 3D space  (Low freq. x High freq. x REM metric)\n",
    "    bidx_active = (pred_2D == 0)\n",
    "    stage_coord_active = stage_coord[bidx_active, :]\n",
    "    # pylint: disable=unused-variable\n",
    "    print(\"classify Wake and REM\")\n",
    "    pred_active, pred_active_proba, mm_active, cc_active, ww_active = classify_Wake_and_REM(\n",
    "        stage_coord_active, rem_floor)\n",
    "\n",
    "    # If the z values of the both clusters are negative or zero, it means there is no REM cluster\n",
    "    if np.all(mm_active[:, 2] <= 0):\n",
    "        # process for data NOT having effective REM cluster\n",
    "        print_log('No effective REM cluster was found.')\n",
    "\n",
    "        pred_2D, pred_2D_proba, mm_2D, cc_2D, pred_3D, pred_3D_proba, mm_3D, cc_3D = classify_two_stages(\n",
    "            stage_coord, pred_2D, mm_2D, cc_2D, mm_active, cc_active)\n",
    "\n",
    "    else:\n",
    "        # process for data having effective REM culster (this is the standard process)\n",
    "\n",
    "        # construct 3D means and covariances from mm_2D and mm_active\n",
    "        # Wake, REM, NREM\n",
    "        mm_3D = np.vstack(\n",
    "            [mm_active, np.mean(stage_coord[pred_2D == 1], axis=0)])\n",
    "        cc_3D = np.vstack(\n",
    "            [cc_active, [np.cov(stage_coord[pred_2D == 1], rowvar=False)]])\n",
    "\n",
    "        # three cluster weights; Wake, REM, NREM\n",
    "        weights_3c = np.array([np.sum(pred_active == 0), np.sum(\n",
    "            pred_active == 1), np.sum(pred_2D == 1)])/ndata\n",
    "\n",
    "        # 3-stage classification: classify REM, Wake, and NREM by Gaussian HMM on the 3D space\n",
    "        try:\n",
    "            pred_3D, pred_3D_proba, mm_3D, cc_3D = classify_three_stages(\n",
    "                stage_coord, mm_3D, cc_3D, weights_3c, max_prn_ax_len)\n",
    "        except ValueError as valerr:\n",
    "            if valerr.args[0] == 'Invalid_REM_Cluster':\n",
    "                print_log('REM cluster is invalid.')\n",
    "                pred_2D, pred_2D_proba, mm_2D, cc_2D, pred_3D, pred_3D_proba, mm_3D, cc_3D = classify_two_stages(\n",
    "                    stage_coord, pred_2D, mm_2D, cc_2D, mm_active, cc_active)\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "    return pred_2D, pred_2D_proba, mm_2D, cc_2D, pred_3D, pred_3D_proba, mm_3D, cc_3D\n",
    "\n",
    "\n",
    "def draw_scatter_plots(path2figures, stage_coord, pred2, means2, covars2, c_pred3, c_means, c_covars, draw_pdf_plot=False):\n",
    "    print_log('Drawing scatter plots')\n",
    "\n",
    "    colors = [COLOR_WAKE, COLOR_NREM]\n",
    "    axes = [0, 1]\n",
    "    points = stage_coord[:, np.r_[axes]]\n",
    "    fig = plot_scatter2D(points, pred2, means2, covars2,\n",
    "                         colors, XLABEL, YLABEL, diag_line=True)\n",
    "    _savefig(path2figures, 'ScatterPlot2D_LowFreq-HighFreq_Axes_Active-NREM', fig, draw_pdf_plot)\n",
    "\n",
    "    points_active = stage_coord[((c_pred3 == 0) | (c_pred3 == 1)), :]\n",
    "    pred_active = c_pred3[((c_pred3 == 0) | (c_pred3 == 1))]\n",
    "\n",
    "    axes = [0, 2]  # Low-freq axis & REM axis\n",
    "    points_prj = stage_coord[:, np.r_[axes]]\n",
    "    colors = [COLOR_WAKE, COLOR_REM, COLOR_NREM]\n",
    "    mm = np.array([m[np.r_[axes]] for m in c_means[np.r_[0, 1, 2]]])\n",
    "    cc = np.array([c[np.r_[axes]][:, np.r_[axes]]\n",
    "                   for c in c_covars[np.r_[0, 1, 2]]])\n",
    "    fig = plot_scatter2D(points_prj, c_pred3, mm,\n",
    "                         cc, colors, XLABEL, ZLABEL)\n",
    "    _savefig(path2figures, 'ScatterPlot2D_LowFreq-REM_axes', fig, draw_pdf_plot)\n",
    "\n",
    "    axes = [1, 2]  # High-freq axis & REM axis\n",
    "    points_prj = stage_coord[:, np.r_[axes]]\n",
    "    mm = np.array([m[np.r_[axes]] for m in c_means[np.r_[0, 1, 2]]])\n",
    "    cc = np.array([c[np.r_[axes]][:, np.r_[axes]]\n",
    "                   for c in c_covars[np.r_[0, 1, 2]]])\n",
    "    fig = plot_scatter2D(points_prj, c_pred3, mm,\n",
    "                         cc, colors, YLABEL, ZLABEL)\n",
    "    _savefig(path2figures, 'ScatterPlot2D_HighFreq-REM_axes', fig, draw_pdf_plot)\n",
    "\n",
    "    axes = [0, 1]  # Low-freq axis & High-freq axis\n",
    "    points_prj = stage_coord[:, np.r_[axes]]\n",
    "    colors = [COLOR_WAKE, COLOR_REM, COLOR_NREM]\n",
    "    mm_proj = np.array([m[np.r_[axes]] for m in c_means[np.r_[0, 1, 2]]])\n",
    "    cc_proj = np.array([c[np.r_[axes]][:, np.r_[axes]]\n",
    "                        for c in c_covars[np.r_[0, 1, 2]]])\n",
    "    fig = plot_scatter2D(points_prj, c_pred3, mm_proj,\n",
    "                         cc_proj, colors, XLABEL, YLABEL, diag_line=True)\n",
    "    _savefig(path2figures, 'ScatterPlot2D_LowFreq-HighFreq_axes_Wake_REM_NREM', fig, draw_pdf_plot)\n",
    "\n",
    "    colors = [COLOR_WAKE, COLOR_REM, COLOR_NREM]\n",
    "    colors_light = [lighten_color(c) for c in colors]\n",
    "    fig = Figure(figsize=(SCATTER_PLOT_FIG_WIDTH,\n",
    "                          SCATTER_PLOT_FIG_HEIGHT), dpi=FIG_DPI, facecolor='w')\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.view_init(elev=10, azim=-135)\n",
    "\n",
    "    ax.set_xlim(-20, 20)\n",
    "    ax.set_ylim(-20, 20)\n",
    "    ax.set_zlim(-20, 20)\n",
    "    ax.set_xlabel(XLABEL, fontsize=10, rotation=0)\n",
    "    ax.set_ylabel(YLABEL, fontsize=10, rotation=0)\n",
    "    ax.set_zlabel(ZLABEL, fontsize=10, rotation=0)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "\n",
    "    for c in set(c_pred3):\n",
    "        t_points = stage_coord[c_pred3 == c]\n",
    "        ax.scatter3D(t_points[:, 0], t_points[:, 1], min(\n",
    "            ax.get_zlim()), s=0.005, color=colors_light[c])\n",
    "        ax.scatter3D(t_points[:, 0], max(ax.get_ylim()),\n",
    "                     t_points[:, 2], s=0.005, color=colors_light[c])\n",
    "        ax.scatter3D(max(ax.get_xlim()),\n",
    "                     t_points[:, 1], t_points[:, 2], s=0.005, color=colors_light[c])\n",
    "\n",
    "        ax.scatter3D(t_points[:, 0], t_points[:, 1],\n",
    "                     t_points[:, 2], s=0.01, color=colors[c])\n",
    "\n",
    "    _savefig(path2figures, 'ScatterPlot3D', fig, draw_pdf_plot)\n",
    "\n",
    "\n",
    "def _savefig(output_dir, basefilename, fig, draw_pdf_plot):\n",
    "    # PNG\n",
    "    filename = f'{basefilename}.png'\n",
    "    fig.savefig(os.path.join(output_dir, filename), pad_inches=0,\n",
    "                bbox_inches='tight', dpi=100)\n",
    "    # PDF\n",
    "    if draw_pdf_plot:\n",
    "        filename = f'{basefilename}.pdf'\n",
    "        fig.savefig(os.path.join(output_dir, 'pdf', filename), pad_inches=0,\n",
    "                    bbox_inches='tight', dpi=100)\n",
    "\n",
    "def find_edf_files(data_dir):\n",
    "    \"\"\"returns list of edf files in the directory\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): A path to the data directory\n",
    "\n",
    "    Returns:\n",
    "        [list]: A list returned by glob()\n",
    "    \"\"\"\n",
    "    return glob(os.path.join(data_dir, '*.edf'))\n",
    "\n",
    "def lighten_color(hex):\n",
    "    return rgb_to_hex(tuple([int(x+(255-x)*0.5) for x in hex_to_rgb(hex)]))\n",
    "\n",
    "\n",
    "def hex_to_rgb(hex_code):\n",
    "    h = hex_code.lstrip('#')\n",
    "    rgb = tuple(int(h[i:i+2], 16) for i in (0, 2, 4))\n",
    "    return rgb\n",
    "\n",
    "\n",
    "def rgb_to_hex(rgb_tuple):\n",
    "    return '#%02x%02x%02x' % rgb_tuple\n",
    "\n",
    "\n",
    "def voltage_normalize(v_mat):\n",
    "    v_array = v_mat.flatten()\n",
    "    v_array = v_array[~np.isnan(v_array)]\n",
    "    bidx_over = v_array > (np.mean(v_array)+3*np.std(v_array))\n",
    "    bidx_under = v_array < (np.mean(v_array)-3*np.std(v_array))\n",
    "    bidx_valid = ~(bidx_over | bidx_under)\n",
    "    v_mat_norm = (\n",
    "        v_mat - np.mean(v_array[bidx_valid]))/np.std(v_array[bidx_valid])\n",
    "\n",
    "    return v_mat_norm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58bca97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assures frequency bins compatibe among different sampling frequencies\n",
    "epoch_len_sec = 8\n",
    "sample_freq = 128\n",
    "n_fft = int(256 * sample_freq/100)\n",
    "# same frequency bins given by signal.welch()\n",
    "freq_bins = 1/(n_fft/sample_freq)*np.arange(0, 129)\n",
    "bidx_sleep_freq = (freq_bins < 4) | ((freq_bins > 10) &\n",
    "                                     (freq_bins < 20))  # without theta, 37 bins\n",
    "bidx_active_freq = (freq_bins > 30)  # 52 bins\n",
    "bidx_theta_freq = (freq_bins >= 4) & (freq_bins < 10)  # 15 bins\n",
    "bidx_delta_freq = (freq_bins < 4)  # 11 bins\n",
    "bidx_muscle_freq = (freq_bins > 30)  # 52 bins\n",
    "\n",
    "n_active_freq = np.sum(bidx_active_freq)\n",
    "n_sleep_freq = np.sum(bidx_sleep_freq)\n",
    "n_theta_freq = np.sum(bidx_theta_freq)\n",
    "n_delta_freq = np.sum(bidx_delta_freq)\n",
    "n_muscle_freq = np.sum(bidx_muscle_freq)\n",
    "\n",
    "rem_floor = np.sum(np.sqrt([n_muscle_freq, n_theta_freq]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42334d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_edf(idx,edf,epoch_num,sample_freq,epoch_len_sec,result_dir,device_id,data_dir,offset_in_msec=0):\n",
    "    raw = mne.io.read_raw_edf(edf)\n",
    "    measurement_start_datetime = raw.info['meas_date']\n",
    "    eegname = 'EEG_{0}'.format(idx)\n",
    "    emgname = 'EMG_{0}'.format(idx)\n",
    "    eeg = raw.get_data(eegname)\n",
    "    #print(eeg.shape)\n",
    "    emg = raw.get_data(emgname)\n",
    "    raw.close()\n",
    "    start_idx=int(offset_in_msec*sample_freq/1000)\n",
    "    actual_epoch_num=int((eeg.shape[1]-start_idx)/sample_freq/epoch_len_sec)\n",
    "    if epoch_num>actual_epoch_num:\n",
    "        epoch_num=actual_epoch_num\n",
    "    end_idx=start_idx+epoch_num*sample_freq*epoch_len_sec\n",
    "    eeg=eeg[:,start_idx:end_idx]\n",
    "    emg=emg[:,start_idx:end_idx]\n",
    "    eeg_vm = eeg.reshape(-1, epoch_len_sec * int(sample_freq))\n",
    "    emg_vm = emg.reshape(-1, epoch_len_sec * int(sample_freq))\n",
    "    os.makedirs(os.path.join(data_dir,\"pkl\"),exist_ok=True)\n",
    "    os.makedirs(os.path.join(result_dir,\"pkl\"),exist_ok=True)\n",
    "    eeg_pkl_path=os.path.join(result_dir,'pkl', f'{device_id}_EEG.pkl')\n",
    "    #eeg_pkl_path = os.path.join(data_dir, 'pkl', f'{device_id}_EEG.pkl')\n",
    "    emg_pkl_path=os.path.join(result_dir,'pkl', f'{device_id}_EMG.pkl')\n",
    "    #emg_pkl_path = os.path.join(data_dir, 'pkl', f'{device_id}_EEG.pkl')\n",
    "\n",
    "\n",
    "    eeg_vm_org = eeg_vm[:epoch_num,]\n",
    "    emg_vm_org = emg_vm[:epoch_num,]\n",
    "\n",
    "    with open(eeg_pkl_path, 'wb') as pkl:\n",
    "        pickle.dump(eeg_vm_org, pkl)\n",
    "    with open(emg_pkl_path, 'wb') as pkl:\n",
    "        pickle.dump(emg_vm_org, pkl)\n",
    "\n",
    "    print_log('Applying the optional filter on the EEG signal')\n",
    "    epoch_sd = np.apply_along_axis(np.nanstd, 1 ,eeg_vm_org)\n",
    "    med_sd = np.median(epoch_sd)\n",
    "    bidx_no_eeg_signal = (epoch_sd / med_sd) < 0.3 # A definition of \"NO signal of EEG\"\n",
    "    eeg_vm_org[bidx_no_eeg_signal, :] = np.nan\n",
    "    print_log(f'The number of epochs with no EEG signal: {np.sum(bidx_no_eeg_signal)}')\n",
    "\n",
    "    # recover nans in the data if possible\n",
    "    nan_ratio_eeg = np.apply_along_axis(et.patch_nan, 1, eeg_vm_org)\n",
    "    nan_ratio_emg = np.apply_along_axis(et.patch_nan, 1, emg_vm_org)\n",
    "\n",
    "    # exclude unrecoverable epochs as unknown\n",
    "    bidx_unknown = np.apply_along_axis(np.any, 1, np.isnan(\n",
    "        eeg_vm_org)) | np.apply_along_axis(np.any, 1, np.isnan(emg_vm_org))\n",
    "    eeg_vm = eeg_vm_org[~bidx_unknown, :]\n",
    "    emg_vm = emg_vm_org[~bidx_unknown, :]\n",
    "\n",
    "    # make data comparable among different mice. Not necessary for staging,\n",
    "    # but convenient for subsequnet analyses.\n",
    "    eeg_vm_norm = voltage_normalize(eeg_vm)\n",
    "    emg_vm_norm = voltage_normalize(emg_vm)\n",
    "\n",
    "    # remove extreme voltages (e.g. heart beat) from EMG\n",
    "    print_log('Applying the optional filter on the EMG signal')\n",
    "    np.apply_along_axis(remove_extreme_voltage, 1, emg_vm_norm, sample_freq)\n",
    "\n",
    "    # power-spectrum normalization of EEG and EMG\n",
    "    spec_norm_eeg = spectrum_normalize(eeg_vm_norm, n_fft, sample_freq)\n",
    "    spec_norm_emg = spectrum_normalize(emg_vm_norm, n_fft, sample_freq)\n",
    "    psd_norm_mat_eeg = spec_norm_eeg['psd']\n",
    "    psd_norm_mat_emg = spec_norm_emg['psd']\n",
    "\n",
    "    # remove extreme powers\n",
    "    extrp_ratio_eeg = np.apply_along_axis(\n",
    "        remove_extreme_power, 1, psd_norm_mat_eeg)\n",
    "    extrp_ratio_emg = np.apply_along_axis(\n",
    "        remove_extreme_power, 1, psd_norm_mat_emg)\n",
    "\n",
    "    # save the PSD matrices and associated factors for subsequent analyses\n",
    "    ## set bidx_unknown; other factors were set by spectrum_normalize()\n",
    "    spec_norm_eeg['bidx_unknown'] = bidx_unknown\n",
    "    spec_norm_emg['bidx_unknown'] = bidx_unknown\n",
    "    pickle_powerspec_matrices(\n",
    "        spec_norm_eeg, spec_norm_emg, result_dir, device_id)\n",
    "\n",
    "    # spread epochs on the 3D (Low freq. x High freq. x REM metric) space\n",
    "    psd_mat = np.concatenate([\n",
    "        psd_norm_mat_eeg.reshape(*psd_norm_mat_eeg.shape, 1),\n",
    "        psd_norm_mat_emg.reshape(*psd_norm_mat_emg.shape, 1)\n",
    "    ], axis=2)\n",
    "    stage_coord = np.array([(\n",
    "        np.sum(y[bidx_sleep_freq, 0])/np.sqrt(n_sleep_freq),\n",
    "        np.sum(y[bidx_active_freq, 0])/np.sqrt(n_active_freq),\n",
    "        np.sum(y[bidx_theta_freq, 0])/np.sqrt(n_theta_freq)-np.sum(y[bidx_delta_freq, 0]) /\n",
    "        np.sqrt(n_delta_freq) -\n",
    "        np.sum(y[bidx_muscle_freq, 1]) / np.sqrt(n_muscle_freq)\n",
    "    ) for y in psd_mat])\n",
    "    ndata = len(stage_coord)\n",
    "\n",
    "    # cancel the weight bias of active/NREM clusters\n",
    "    cwb = cancel_weight_bias(stage_coord[:, 0:2])\n",
    "    stage_coord[:, 0:2] = cwb['stage_coord_2D']\n",
    "\n",
    "    # run the classification process\n",
    "    pred_2D, pred_2D_proba, means_2D, covars_2D, pred_3D, pred_3D_proba, means_3D, covars_3D = classification_process(\n",
    "            stage_coord, rem_floor)\n",
    "\n",
    "\n",
    "    # output staging result\n",
    "    stage_proba = np.zeros(3*epoch_num).reshape(epoch_num, 3)\n",
    "    proba_REM = pred_3D_proba[:, 1]\n",
    "    proba_WAKE = pred_3D_proba[:, 0]\n",
    "    proba_NREM = pred_3D_proba[:, 2]\n",
    "    stage_proba[~bidx_unknown, 0] = proba_REM\n",
    "    stage_proba[~bidx_unknown, 1] = proba_WAKE\n",
    "    stage_proba[~bidx_unknown, 2] = proba_NREM\n",
    "\n",
    "    stage_call = np.repeat('Unknown', epoch_num)\n",
    "    stage_call[~bidx_unknown] = np.array(\n",
    "        [STAGE_LABELS[y] for y in pred_3D])\n",
    "\n",
    "    # Print a brief result\n",
    "    print_log(f'2-stage means:\\n {means_2D}')\n",
    "    print_log(f'2-stage covars:\\n {covars_2D}')\n",
    "    print_log('\\n')\n",
    "    print_log(f'3-stage means:\\n{means_3D}')\n",
    "    print_log(f'3-stage covars:\\n{covars_3D}')\n",
    "\n",
    "    # Compose stage table\n",
    "    extreme_power_ratio = np.zeros(2*epoch_num).reshape(epoch_num, 2)\n",
    "    extreme_power_ratio[~bidx_unknown, 0] = extrp_ratio_eeg\n",
    "    extreme_power_ratio[~bidx_unknown, 1] = extrp_ratio_emg\n",
    "\n",
    "    stage_table = pd.DataFrame({'Stage': stage_call,\n",
    "                                'REM probability': stage_proba[:, 0],\n",
    "                                'NREM probability': stage_proba[:, 2],\n",
    "                                'Wake probability': stage_proba[:, 1],\n",
    "                                'NaN ratio EEG-TS': nan_ratio_eeg,\n",
    "                                'NaN ratio EMG-TS': nan_ratio_emg,\n",
    "                                'Outlier ratio EEG-TS': extreme_power_ratio[:, 0],\n",
    "                                'Outlier ratio EMG-TS': extreme_power_ratio[:, 1]})\n",
    "    stage_file_path = os.path.join(result_dir, f'{device_id}.faster2.stage.csv')\n",
    "\n",
    "    with open(stage_file_path, 'w', encoding='UTF-8') as f:\n",
    "        f.write(f'# Start: {measurement_start_datetime} \\n')\n",
    "        f.write(f'# Epoch num: {epoch_num}  Epoch length: {epoch_len_sec} [s]\\n')\n",
    "        f.write(f'# Sampling frequency: {sample_freq} [Hz]\\n')\n",
    "        f.write(f'# Staged by {FASTER2_NAME}\\n')\n",
    "    with open(stage_file_path, 'a') as f:\n",
    "        print(f)\n",
    "        print(type(f))\n",
    "        print(type(stage_table))\n",
    "        stage_table.to_csv(f, header=True, index=False)\n",
    "        #stage_table.to_csv(f, header=True, index=False, line_terminator='\\n')\n",
    "\n",
    "    path2figures = os.path.join(result_dir, 'figure', f'{device_id}')\n",
    "    os.makedirs(path2figures, exist_ok=True)\n",
    "\n",
    "    # draw the bias histogram\n",
    "    plot_hist_on_separation_axis(path2figures, cwb['proj_data'], cwb['means'], cwb['covars'], cwb['weights']) \n",
    "\n",
    "    # draw scatter plots\n",
    "    draw_scatter_plots(path2figures, stage_coord, pred_2D, means_2D, covars_2D, pred_3D, means_3D, covars_3D)\n",
    "\n",
    "    # pickle cluster parameters\n",
    "    pickle_cluster_params(means_2D, covars_2D, means_3D, covars_3D, result_dir, device_id)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8900f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters injected by papermill or CLI\n",
    "prj_dir = locals().get(\"prj_dir\", \"/p-antipsychotics-sleep/raw_data/kaist\")\n",
    "result_dir_name = locals().get(\"result_dir_name\", \"result\")\n",
    "epoch_len_sec = locals().get(\"epoch_len_sec\", 8)\n",
    "sample_freq = locals().get(\"sample_freq\", 128)\n",
    "overwrite = locals().get(\"overwrite\", False)\n",
    "offset_in_msec = locals().get(\"offset_in_msec\", 0)\n",
    "\n",
    "crawl_prj_for_preprocess_edf(\n",
    "    prj_dir,\n",
    "    result_dir_name,\n",
    "    epoch_len_sec,\n",
    "    sample_freq=sample_freq,\n",
    "    is_overwite=overwrite,\n",
    "    offset_in_msec=offset_in_msec,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64e12d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/p-antipsychotics-sleep/raw_data/kaist/20251120_KA001-004/data/20251120_KA001-004_C1_20251121_0659.edf\n",
      "Ch0\n",
      "Extracting EDF parameters from /p-antipsychotics-sleep/raw_data/kaist/20251120_KA001-004/data/20251120_KA001-004_C1_20251121_0659.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Applying the optional filter on the EEG signal\n",
      "The number of epochs with no EEG signal: 0\n",
      "Applying the optional filter on the EMG signal\n",
      "Saving PSD files\n",
      "Saving the EEG PSD matrix into /p-antipsychotics-sleep/raw_data/kaist/20251120_KA001-004/result/PSD/Ch0_EEG_PSD.pkl\n",
      "Saving the EMG PSD matrix into /p-antipsychotics-sleep/raw_data/kaist/20251120_KA001-004/result/PSD/Ch0_EMG_PSD.pkl\n",
      "Estimate the bias of the two cluster means\n",
      "Estimated bias: 0.2525074846393874\n",
      "classify active and NREM\n",
      "Initialize active/NREM clusters with the diagonal line\n",
      "classify Wake and REM\n",
      "Classify REM and Wake clusters with GMM\n",
      "Classify REM, Wake, and NREM by Gaussian HMM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model is not converging.  Current: -1629140.6276807406 is not greater than -1545147.617589524. Delta is -83993.01009121654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-stage means:\n",
      " [[-3.89268075  1.56408334]\n",
      " [ 3.93686728 -1.21142719]]\n",
      "2-stage covars:\n",
      " [[[3.55096284 1.70800358]\n",
      "  [1.70800358 7.94878852]]\n",
      "\n",
      " [[9.79981055 5.32973048]\n",
      "  [5.32973048 8.44204267]]]\n",
      "\n",
      "\n",
      "3-stage means:\n",
      "[[-4.13981282  2.13202418 -7.61062683]\n",
      " [-4.16658802 -0.21423975 13.66234877]\n",
      " [ 3.94682668 -1.20308277  5.23015322]]\n",
      "3-stage covars:\n",
      "[[[ 1.97220645e+02  2.28918747e+02 -2.46289591e+01]\n",
      "  [ 2.28918747e+02  2.90118803e+02 -4.15912166e+01]\n",
      "  [-2.46289591e+01 -4.15912166e+01  2.49589494e+01]]\n",
      "\n",
      " [[ 4.39978973e+00 -1.87936722e-01 -4.42189143e-01]\n",
      "  [-1.87936722e-01  8.52566277e+00 -2.01004392e-02]\n",
      "  [-4.42189143e-01 -2.01004392e-02  8.48691219e+00]]\n",
      "\n",
      " [[ 7.50331138e+01  8.74540258e+01 -3.96537663e+01]\n",
      "  [ 8.74540258e+01  1.19766113e+02 -5.84542701e+01]\n",
      "  [-3.96537663e+01 -5.84542701e+01  3.92456131e+01]]]\n",
      "<_io.TextIOWrapper name='/p-antipsychotics-sleep/raw_data/kaist/20251120_KA001-004/result/Ch0.faster2.stage.csv' mode='a' encoding='UTF-8'>\n",
      "<class '_io.TextIOWrapper'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Drawing scatter plots\n",
      "Saving the cluster parameters into /p-antipsychotics-sleep/raw_data/kaist/20251120_KA001-004/result/cluster_params/Ch0_cluster_params.pkl\n",
      "/p-antipsychotics-sleep/raw_data/kaist/20251120_KA001-004/data/20251120_KA001-004_C2_20251121_0659.edf\n",
      "Ch1\n",
      "Extracting EDF parameters from /p-antipsychotics-sleep/raw_data/kaist/20251120_KA001-004/data/20251120_KA001-004_C2_20251121_0659.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Applying the optional filter on the EEG signal\n",
      "The number of epochs with no EEG signal: 0\n",
      "Applying the optional filter on the EMG signal\n",
      "Saving PSD files\n",
      "Saving the EEG PSD matrix into /p-antipsychotics-sleep/raw_data/kaist/20251120_KA001-004/result/PSD/Ch1_EEG_PSD.pkl\n",
      "Saving the EMG PSD matrix into /p-antipsychotics-sleep/raw_data/kaist/20251120_KA001-004/result/PSD/Ch1_EMG_PSD.pkl\n",
      "Estimate the bias of the two cluster means\n",
      "Estimated bias: 0.2575668671966399\n",
      "classify active and NREM\n",
      "Initialize active/NREM clusters with the diagonal line\n",
      "classify Wake and REM\n",
      "Classify REM and Wake clusters with GMM\n",
      "Classify REM, Wake, and NREM by Gaussian HMM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model is not converging.  Current: -1397391.5354502366 is not greater than -1327824.0005018285. Delta is -69567.53494840814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-stage means:\n",
      " [[-2.96504341  1.59869415]\n",
      " [ 3.09599893 -1.35592619]]\n",
      "2-stage covars:\n",
      " [[[ 5.30184384  3.57037938]\n",
      "  [ 3.57037938  8.70058843]]\n",
      "\n",
      " [[17.55087331 12.36932082]\n",
      "  [12.36932082 14.81654669]]]\n",
      "\n",
      "\n",
      "3-stage means:\n",
      "[[-2.75423082  2.64328567 -7.04658669]\n",
      " [-4.53393678  0.50608025 13.34618073]\n",
      " [ 3.10530894 -1.3517144   4.33428252]]\n",
      "3-stage covars:\n",
      "[[[ 5.43447707e+02  5.98495753e+02  1.09599379e+01]\n",
      "  [ 5.98495753e+02  6.75393688e+02  2.61711518e+00]\n",
      "  [ 1.09599379e+01  2.61711518e+00  1.86728348e+01]]\n",
      "\n",
      " [[ 1.09553880e+01 -2.65949598e-16  1.74162640e-15]\n",
      "  [-3.05736779e-16  1.09553880e+01 -2.15103939e-15]\n",
      "  [ 1.89456606e-15 -2.38160898e-15  1.09553880e+01]]\n",
      "\n",
      " [[ 1.66334662e+01  1.48419188e+01 -3.00605646e+00]\n",
      "  [ 1.48419188e+01  2.79491643e+01 -1.51759689e+01]\n",
      "  [-3.00605646e+00 -1.51759689e+01  2.04796129e+01]]]\n",
      "<_io.TextIOWrapper name='/p-antipsychotics-sleep/raw_data/kaist/20251120_KA001-004/result/Ch1.faster2.stage.csv' mode='a' encoding='UTF-8'>\n",
      "<class '_io.TextIOWrapper'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Drawing scatter plots\n",
      "Saving the cluster parameters into /p-antipsychotics-sleep/raw_data/kaist/20251120_KA001-004/result/cluster_params/Ch1_cluster_params.pkl\n",
      "/p-antipsychotics-sleep/raw_data/kaist/20251120_KA001-004/data/20251120_KA001-004_C3_20251121_0659.edf\n",
      "Ch2\n",
      "Extracting EDF parameters from /p-antipsychotics-sleep/raw_data/kaist/20251120_KA001-004/data/20251120_KA001-004_C3_20251121_0659.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Applying the optional filter on the EEG signal\n",
      "The number of epochs with no EEG signal: 0\n",
      "Applying the optional filter on the EMG signal\n",
      "Saving PSD files\n",
      "Saving the EEG PSD matrix into /p-antipsychotics-sleep/raw_data/kaist/20251120_KA001-004/result/PSD/Ch2_EEG_PSD.pkl\n",
      "Saving the EMG PSD matrix into /p-antipsychotics-sleep/raw_data/kaist/20251120_KA001-004/result/PSD/Ch2_EMG_PSD.pkl\n",
      "Estimate the bias of the two cluster means\n",
      "Estimated bias: 0.5188161655658856\n",
      "classify active and NREM\n",
      "Initialize active/NREM clusters with the diagonal line\n",
      "classify Wake and REM\n",
      "Classify REM and Wake clusters with GMM\n",
      "Classify REM, Wake, and NREM by Gaussian HMM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model is not converging.  Current: -1275746.1211524303 is not greater than -1273487.9274916253. Delta is -2258.193660805002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-stage means:\n",
      " [[-3.94318376  1.28839122]\n",
      " [ 2.73996412 -1.27390965]]\n",
      "2-stage covars:\n",
      " [[[ 8.91690753  4.96502583]\n",
      "  [ 4.96502583  9.97698654]]\n",
      "\n",
      " [[ 8.30763522  6.337278  ]\n",
      "  [ 6.337278   11.63294245]]]\n",
      "\n",
      "\n",
      "3-stage means:\n",
      "[[-5.01212345  1.1431659  -9.15767857]\n",
      " [-2.91128128 -0.1026919  11.9460041 ]\n",
      " [ 2.79925979 -1.42489872  5.05331422]]\n",
      "3-stage covars:\n",
      "[[[ 2.96442494e+01  5.51472244e+00  2.46608931e-02]\n",
      "  [ 5.51472244e+00  9.80088566e+00 -5.53336473e+00]\n",
      "  [ 2.46608931e-02 -5.53336473e+00  2.72254521e+01]]\n",
      "\n",
      " [[ 8.61811719e+00 -2.07191925e+00 -1.19498436e+00]\n",
      "  [-2.07191925e+00  1.25471408e+01 -5.25514630e-01]\n",
      "  [-1.19498436e+00 -5.25514630e-01  1.41862169e+01]]\n",
      "\n",
      " [[ 4.35733947e+01  5.09273650e+01 -8.74294003e+00]\n",
      "  [ 5.09273650e+01  7.16639716e+01 -1.88322336e+01]\n",
      "  [-8.74294003e+00 -1.88322336e+01  1.61003379e+01]]]\n",
      "<_io.TextIOWrapper name='/p-antipsychotics-sleep/raw_data/kaist/20251120_KA001-004/result/Ch2.faster2.stage.csv' mode='a' encoding='UTF-8'>\n",
      "<class '_io.TextIOWrapper'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Drawing scatter plots\n",
      "Saving the cluster parameters into /p-antipsychotics-sleep/raw_data/kaist/20251120_KA001-004/result/cluster_params/Ch2_cluster_params.pkl\n",
      "/p-antipsychotics-sleep/raw_data/kaist/20251120_KA001-004/data/20251120_KA001-004_C4_20251121_0659.edf\n",
      "Ch3\n",
      "Extracting EDF parameters from /p-antipsychotics-sleep/raw_data/kaist/20251120_KA001-004/data/20251120_KA001-004_C4_20251121_0659.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Applying the optional filter on the EEG signal\n",
      "The number of epochs with no EEG signal: 0\n",
      "Applying the optional filter on the EMG signal\n",
      "Saving PSD files\n",
      "Saving the EEG PSD matrix into /p-antipsychotics-sleep/raw_data/kaist/20251120_KA001-004/result/PSD/Ch3_EEG_PSD.pkl\n",
      "Saving the EMG PSD matrix into /p-antipsychotics-sleep/raw_data/kaist/20251120_KA001-004/result/PSD/Ch3_EMG_PSD.pkl\n",
      "Estimate the bias of the two cluster means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning: Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated bias: 0.49839837081563915\n",
      "classify active and NREM\n",
      "Initialize active/NREM clusters with the diagonal line\n",
      "classify Wake and REM\n",
      "Classify REM and Wake clusters with GMM\n",
      "Classify REM, Wake, and NREM by Gaussian HMM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model is not converging.  Current: -1260948.0467121517 is not greater than -1260849.4924072747. Delta is -98.55430487706326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-stage means:\n",
      " [[-3.94751927  1.17692335]\n",
      " [ 3.87623548 -0.33454276]]\n",
      "2-stage covars:\n",
      " [[[ 7.59934492  3.69197052]\n",
      "  [ 3.69197052  9.62261437]]\n",
      "\n",
      " [[14.1156202  10.47979193]\n",
      "  [10.47979193 13.99595105]]]\n",
      "\n",
      "\n",
      "3-stage means:\n",
      "[[ -5.13470028   0.6141648  -10.15438861]\n",
      " [ -2.7754298    0.18502861  12.34242145]\n",
      " [  3.86204041  -0.37566479   5.19367669]]\n",
      "3-stage covars:\n",
      "[[[24.30561771  3.56454196  1.69138952]\n",
      "  [ 3.56454196  7.61055346 -3.647628  ]\n",
      "  [ 1.69138952 -3.647628   25.58161414]]\n",
      "\n",
      " [[ 9.43422368  3.69568745 -0.30250105]\n",
      "  [ 3.69568745  7.89363712  0.37205239]\n",
      "  [-0.30250105  0.37205239 12.40858726]]\n",
      "\n",
      " [[12.28252613  5.64003426  6.87403941]\n",
      "  [ 5.64003426 12.46615144 -2.65984376]\n",
      "  [ 6.87403941 -2.65984376 15.70394118]]]\n",
      "<_io.TextIOWrapper name='/p-antipsychotics-sleep/raw_data/kaist/20251120_KA001-004/result/Ch3.faster2.stage.csv' mode='a' encoding='UTF-8'>\n",
      "<class '_io.TextIOWrapper'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Drawing scatter plots\n",
      "Saving the cluster parameters into /p-antipsychotics-sleep/raw_data/kaist/20251120_KA001-004/result/cluster_params/Ch3_cluster_params.pkl\n",
      "/p-antipsychotics-sleep/raw_data/kaist/20251120_KA005-008/data/20251120_KA005-008_C1_20251121_0659.edf\n",
      "Ch0\n",
      "Extracting EDF parameters from /p-antipsychotics-sleep/raw_data/kaist/20251120_KA005-008/data/20251120_KA005-008_C1_20251121_0659.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Applying the optional filter on the EEG signal\n",
      "The number of epochs with no EEG signal: 0\n",
      "Applying the optional filter on the EMG signal\n",
      "Saving PSD files\n",
      "Saving the EEG PSD matrix into /p-antipsychotics-sleep/raw_data/kaist/20251120_KA005-008/result/PSD/Ch0_EEG_PSD.pkl\n",
      "Saving the EMG PSD matrix into /p-antipsychotics-sleep/raw_data/kaist/20251120_KA005-008/result/PSD/Ch0_EMG_PSD.pkl\n",
      "Estimate the bias of the two cluster means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/mixture/_base.py:269: ConvergenceWarning: Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated bias: 0.7053791672451819\n",
      "classify active and NREM\n",
      "Initialize active/NREM clusters with the diagonal line\n",
      "classify Wake and REM\n",
      "Classify REM and Wake clusters with GMM\n",
      "Classify REM, Wake, and NREM by Gaussian HMM\n",
      "2-stage means:\n",
      " [[-2.30313336  2.85801019]\n",
      " [ 1.57321731 -2.04185038]]\n",
      "2-stage covars:\n",
      " [[[ 6.03511666  3.67239639]\n",
      "  [ 3.67239639 12.28972861]]\n",
      "\n",
      " [[12.61846096 10.95777609]\n",
      "  [10.95777609 14.52458201]]]\n",
      "\n",
      "\n",
      "3-stage means:\n",
      "[[-2.89729967  3.8293945  -6.91766077]\n",
      " [-4.16429545 -0.21888622 13.06369802]\n",
      " [ 1.51726171 -2.10721544  4.2964438 ]]\n",
      "3-stage covars:\n",
      "[[[12.28131014  0.93740312  3.79069874]\n",
      "  [ 0.93740312 23.52980699 -0.15895033]\n",
      "  [ 3.79069874 -0.15895033 22.06500285]]\n",
      "\n",
      " [[11.92632621  2.21313563 -0.37081816]\n",
      "  [ 2.21313563 11.60788787  0.39845425]\n",
      "  [-0.37081816  0.39845425 13.91920029]]\n",
      "\n",
      " [[18.4756079  21.37802081  0.44137799]\n",
      "  [21.37802081 34.13305963 -5.5986988 ]\n",
      "  [ 0.44137799 -5.5986988  10.60215933]]]\n",
      "<_io.TextIOWrapper name='/p-antipsychotics-sleep/raw_data/kaist/20251120_KA005-008/result/Ch0.faster2.stage.csv' mode='a' encoding='UTF-8'>\n",
      "<class '_io.TextIOWrapper'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Drawing scatter plots\n",
      "Saving the cluster parameters into /p-antipsychotics-sleep/raw_data/kaist/20251120_KA005-008/result/cluster_params/Ch0_cluster_params.pkl\n",
      "/p-antipsychotics-sleep/raw_data/kaist/20251120_KA005-008/data/20251120_KA005-008_C2_20251121_0659.edf\n",
      "Ch1\n",
      "Extracting EDF parameters from /p-antipsychotics-sleep/raw_data/kaist/20251120_KA005-008/data/20251120_KA005-008_C2_20251121_0659.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Applying the optional filter on the EEG signal\n",
      "The number of epochs with no EEG signal: 3699\n",
      "Applying the optional filter on the EMG signal\n",
      "Saving PSD files\n",
      "Saving the EEG PSD matrix into /p-antipsychotics-sleep/raw_data/kaist/20251120_KA005-008/result/PSD/Ch1_EEG_PSD.pkl\n",
      "Saving the EMG PSD matrix into /p-antipsychotics-sleep/raw_data/kaist/20251120_KA005-008/result/PSD/Ch1_EMG_PSD.pkl\n",
      "Estimate the bias of the two cluster means\n",
      "Estimated bias: -0.4362294979979034\n",
      "classify active and NREM\n",
      "Initialize active/NREM clusters with the diagonal line\n",
      "classify Wake and REM\n",
      "Classify REM and Wake clusters with GMM\n",
      "Classify REM, Wake, and NREM by Gaussian HMM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model is not converging.  Current: -1221637.287987207 is not greater than -1220551.0218082368. Delta is -1086.2661789702252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-stage means:\n",
      " [[-2.00791695  1.36732864]\n",
      " [ 2.66576638 -1.92587904]]\n",
      "2-stage covars:\n",
      " [[[ 5.57452154  4.05187835]\n",
      "  [ 4.05187835  6.13775593]]\n",
      "\n",
      " [[11.50269544  9.5094813 ]\n",
      "  [ 9.5094813  15.82646553]]]\n",
      "\n",
      "\n",
      "3-stage means:\n",
      "[[-2.1977545   2.11996426 -7.43324256]\n",
      " [-3.18472055 -0.62644907 15.62064365]\n",
      " [ 2.49361129 -2.19053299  3.27728175]]\n",
      "3-stage covars:\n",
      "[[[ 7.76926609 -0.50220448  4.02392504]\n",
      "  [-0.50220448  5.20834642 -5.37500413]\n",
      "  [ 4.02392504 -5.37500413 27.65331204]]\n",
      "\n",
      " [[ 5.96478881 -1.55891718 -0.60258664]\n",
      "  [-1.55891718  9.30301302 -0.23763773]\n",
      "  [-0.60258664 -0.23763773  9.82593498]]\n",
      "\n",
      " [[13.98937321  8.83011239 15.11890085]\n",
      "  [ 8.83011239 20.12675731 -1.7127052 ]\n",
      "  [15.11890085 -1.7127052  45.64887199]]]\n",
      "<_io.TextIOWrapper name='/p-antipsychotics-sleep/raw_data/kaist/20251120_KA005-008/result/Ch1.faster2.stage.csv' mode='a' encoding='UTF-8'>\n",
      "<class '_io.TextIOWrapper'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Drawing scatter plots\n",
      "Saving the cluster parameters into /p-antipsychotics-sleep/raw_data/kaist/20251120_KA005-008/result/cluster_params/Ch1_cluster_params.pkl\n",
      "/p-antipsychotics-sleep/raw_data/kaist/20251120_KA005-008/data/20251120_KA005-008_C3_20251121_0659.edf\n",
      "Ch2\n",
      "Extracting EDF parameters from /p-antipsychotics-sleep/raw_data/kaist/20251120_KA005-008/data/20251120_KA005-008_C3_20251121_0659.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Applying the optional filter on the EEG signal\n",
      "The number of epochs with no EEG signal: 0\n",
      "Applying the optional filter on the EMG signal\n",
      "Saving PSD files\n",
      "Saving the EEG PSD matrix into /p-antipsychotics-sleep/raw_data/kaist/20251120_KA005-008/result/PSD/Ch2_EEG_PSD.pkl\n",
      "Saving the EMG PSD matrix into /p-antipsychotics-sleep/raw_data/kaist/20251120_KA005-008/result/PSD/Ch2_EMG_PSD.pkl\n",
      "Estimate the bias of the two cluster means\n",
      "Estimated bias: 1.3481268459877849\n",
      "classify active and NREM\n",
      "Initialize active/NREM clusters with the diagonal line\n",
      "classify Wake and REM\n",
      "Classify REM and Wake clusters with GMM\n",
      "Classify REM, Wake, and NREM by Gaussian HMM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model is not converging.  Current: -1334062.7789356124 is not greater than -1322299.4080426334. Delta is -11763.370892978972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-stage means:\n",
      " [[-2.97549343  2.84644791]\n",
      " [ 1.27173061 -1.71913553]]\n",
      "2-stage covars:\n",
      " [[[11.82333025  9.27851767]\n",
      "  [ 9.27851767 18.69892964]]\n",
      "\n",
      " [[11.97590483 10.66917343]\n",
      "  [10.66917343 14.90477055]]]\n",
      "\n",
      "\n",
      "3-stage means:\n",
      "[[-3.76428789  4.24662563 -8.89867605]\n",
      " [-5.85278478 -2.16324544 13.79647495]\n",
      " [ 1.21552656 -1.9964256   4.93149316]]\n",
      "3-stage covars:\n",
      "[[[147.08241323  88.61499597  35.78440703]\n",
      "  [ 88.61499597  78.27863025   8.53194182]\n",
      "  [ 35.78440703   8.53194182  40.6611643 ]]\n",
      "\n",
      " [[ 22.58224957   2.74093434  -0.90841514]\n",
      "  [  2.74093434  22.23711936   0.96740619]\n",
      "  [ -0.90841514   0.96740619  24.83542271]]\n",
      "\n",
      " [[ 14.76820458   7.70653432   3.56173459]\n",
      "  [  7.70653432   8.38234156  -3.20031541]\n",
      "  [  3.56173459  -3.20031541  14.08997156]]]\n",
      "<_io.TextIOWrapper name='/p-antipsychotics-sleep/raw_data/kaist/20251120_KA005-008/result/Ch2.faster2.stage.csv' mode='a' encoding='UTF-8'>\n",
      "<class '_io.TextIOWrapper'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Drawing scatter plots\n",
      "Saving the cluster parameters into /p-antipsychotics-sleep/raw_data/kaist/20251120_KA005-008/result/cluster_params/Ch2_cluster_params.pkl\n",
      "/p-antipsychotics-sleep/raw_data/kaist/20251120_KA005-008/data/20251120_KA005-008_C4_20251121_0659.edf\n",
      "Ch3\n",
      "Extracting EDF parameters from /p-antipsychotics-sleep/raw_data/kaist/20251120_KA005-008/data/20251120_KA005-008_C4_20251121_0659.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    }
   ],
   "source": [
    "prj_dir=\"/p-antipsychotics-sleep/raw_data/kaist\"\n",
    "result_dir_name=\"result\"\n",
    "epoch_len_sec=8\n",
    "crawl_prj_for_preprocess_edf(prj_dir,result_dir_name,epoch_len_sec,sample_freq=128,is_overwite=False,offset_in_msec=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d207059e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function NDFrame.to_csv at 0x7fcb85d3ba60>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.DataFrame.to_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dd6f17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.4\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "print(matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "216aa978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/site-packages (3.3.4)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.9.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.9/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.9/site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.9/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/site-packages (from matplotlib) (6.4.5)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.18.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Using cached matplotlib-3.9.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "Installing collected packages: matplotlib\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.3.4\n",
      "    Uninstalling matplotlib-3.3.4:\n",
      "      Successfully uninstalled matplotlib-3.3.4\n",
      "Successfully installed matplotlib-3.9.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade matplotlib"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}